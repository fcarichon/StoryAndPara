{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b96d93-6308-4b31-ab1d-9f8ac26443ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict \n",
    "#Import des tokenizers - sent_tokenize pour les phrases et word_tokenize pour les mots avec nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import statistics\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import re\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "#Personalized - tested and no bug functions\n",
    "from Story_characters import Characters\n",
    "from Story_conflict import Conflict\n",
    "from Story_themes import Themes\n",
    "from Story_chronology import Chronology\n",
    "from Story_causality import Causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfb04a0f-a99f-4b35-99fc-b7fbaa2d7503",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_clean(text):\n",
    "    \n",
    "    text = text.replace('@', '')\n",
    "    text = text.replace('#', '')\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fa9311f-81f6-42f0-af5a-9348e7eaf295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "df_train = pd.read_csv(\"data/Train_Post_StoryPara_V1.csv\")\n",
    "df_train['PostText'] = df_train['PostText'].apply(data_clean)\n",
    "df_train['PostText'].replace('', np.nan, inplace=True)\n",
    "df_posts_train = df_train.dropna(subset=['PostText'])\n",
    "\n",
    "###########################################################################\n",
    "df_valid = pd.read_csv(\"data/Valid_Post_StoryPara_V1.csv\")\n",
    "df_valid['PostText'] = df_valid['PostText'].apply(data_clean)\n",
    "df_valid['PostText'].replace('', np.nan, inplace=True)\n",
    "df_posts_valid = df_valid.dropna(subset=['PostText'])\n",
    "\n",
    "###########################################################################\n",
    "df_test = pd.read_csv(\"data/Test_Post_StoryPara_V1.csv\")\n",
    "df_test['PostText'] = df_test['PostText'].apply(data_clean)\n",
    "df_test['PostText'].replace('', np.nan, inplace=True)\n",
    "df_test['PostText'].replace(' ', np.nan, inplace=True)\n",
    "df_posts_test = df_test.dropna(subset=['PostText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d23b80cc-fa3c-4e46-b719-5b5e447cf4bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_posts_train = df_posts_train[\"PostSysID\"]\n",
    "train_list = list(df_posts_train[\"PostText\"])\n",
    "id_posts_valid = df_posts_valid[\"PostSysID\"]\n",
    "valid_list = list(df_posts_valid[\"PostText\"])\n",
    "id_posts_test = df_posts_test[\"PostSysID\"]\n",
    "test_list = list(df_posts_test[\"PostText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c253775a-371a-4de4-9f34-ca745bbd8568",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7998\n",
      "4998\n",
      "3919\n"
     ]
    }
   ],
   "source": [
    "print(len(train_list))\n",
    "print(len(valid_list))\n",
    "print(len(test_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddf6a88-f8e9-48e1-89fb-4e85cb8c2e8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Personnages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbd74d29-bf8f-4afb-aabd-baa16f51f25f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_characters(text_list, dataframe, name_save = 'Test_Story_withVariable'): \n",
    "    \n",
    "    charac_func = Characters()\n",
    "    #For pronouns\n",
    "    first_sing, first_plur, second, third_sing, third_plur = [], [], [], [], []\n",
    "    #Named_entities\n",
    "    bin_ent = []\n",
    "    #most_used_pron : Categorial\n",
    "    cat_most_used = []\n",
    "    #Proportion of sentences with 2 characters\n",
    "    two_charac = []\n",
    "    # Entity as a subject\n",
    "    EN_subj = []\n",
    "    \n",
    "    for i, text in enumerate(text_list):\n",
    "        bin_dict = charac_func.pronouns(text)\n",
    "        first_sing.append(bin_dict[\"first_sing\"])\n",
    "        first_plur.append(bin_dict[\"first_plur\"])\n",
    "        second.append(bin_dict[\"second\"])\n",
    "        third_sing.append(bin_dict[\"third_sing\"])\n",
    "        third_plur.append(bin_dict[\"third_plur\"])\n",
    "        \n",
    "        bin_ent.append(charac_func.named_entities(text))\n",
    "        cat_most_used.append(charac_func.most_used_pron(text))\n",
    "        two_charac.append(charac_func.prop_same_sent(text))\n",
    "        EN_subj.append(charac_func.EN_as_subj(text))\n",
    "        \n",
    "    # Appending all list to dataframe and save\n",
    "    dataframe[\"first_person_sing\"] = first_sing\n",
    "    dataframe[\"first_person_plur\"] = first_plur\n",
    "    dataframe[\"second_person\"] = second\n",
    "    dataframe[\"third_person_sing\"] = third_sing\n",
    "    dataframe[\"third_person_plur\"] = third_plur\n",
    "    \n",
    "    dataframe[\"Binary_Entity\"] = bin_ent\n",
    "    dataframe[\"Most_common_pronoun\"] = cat_most_used\n",
    "    dataframe[\"Ratio_sentences_2_persos\"] = two_charac\n",
    "    dataframe[\"EN_sent_subj\"] = EN_subj\n",
    "    \n",
    "    #dataframe.to_csv(f'data/{name_save}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03382510-f0ab-4f42-b1f2-054943758eea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "190ee6ca-090a-4b0c-a761-a16b23b2c45a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_themes(train_list, text_list, dataframe, name_save = 'Test_Story_withVariable'):\n",
    "    \n",
    "    #See the Data_Processing file for the parameters selection\n",
    "    theme_func = Themes(train_list, num_k=15, ban_list = ['DET', 'PUNCT', 'AUX'], alpha=0.01, beta=0.01)\n",
    "    diversity_, homogeneity_, consistence_ = [], [], []\n",
    "    for text in text_list:\n",
    "        diversity_.append(theme_func.diversity(text))\n",
    "        homogeneity_.append(theme_func.homogeneity(text))\n",
    "        consistence_.append(theme_func.consistence(text))\n",
    "        \n",
    "    dataframe[\"Intrigue_Diversity\"] = diversity_\n",
    "    dataframe[\"Intrigue_Sentence_Homogeneity\"] = homogeneity_\n",
    "    dataframe[\"Intrigue_Consistence\"] = consistence_\n",
    "    \n",
    "    #dataframe.to_csv(f'data/{name_save}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2464b11-f87e-48c2-8b1c-df7619358f22",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecd4c61a-e419-4e35-8115-da5b01e7f22e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_conflict(text_list, dataframe, name_save = 'Test_Story_withVariable'):\n",
    "    \n",
    "    conflict_func = Conflict(increase_ratio=2, n_window=1)\n",
    "    conflictual_envent, conflict_2_persos, conflict_increase, intrigue_change_sent = [], [], [], []\n",
    "    for i, text in enumerate(text_list):\n",
    "        intrigue_change_sent.append(conflict_func.change_sent_status(text))\n",
    "        conflictual_envent.append(conflict_func.conflict_event(text))\n",
    "        conflict_2_persos.append(conflict_func.sent_characters(text))\n",
    "        conflict_increase.append(conflict_func.increase_sent(text))\n",
    "        \n",
    "    dataframe[\"Intrigue_Prop_Change_Sent\"] = intrigue_change_sent\n",
    "    dataframe[\"Conflictual_Event\"] = conflictual_envent\n",
    "    dataframe[\"Conflict_two_persos\"] = conflict_2_persos\n",
    "    dataframe[\"Climax_increase\"] = conflict_increase\n",
    "    \n",
    "    #dataframe.to_csv(f'data/{name_save}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4239cd-703c-4d6f-af0c-ea99e874e7f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cb3c55c-81ea-4793-aef0-4c4fe0f3436f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_causality(text_list, dataframe, name_save = 'Test_Story_withVariable'):\n",
    "    \n",
    "    causal_func = Causality()\n",
    "    causal_coherence_, total_length_causal, causal_intra_sent = [], [], []\n",
    "    for text in text_list:\n",
    "        causal_coherence_.append(causal_func.causal_chorence(text))\n",
    "        total_length_causal.append(causal_func.causal_length(text))\n",
    "        causal_intra_sent.append(causal_func.causal_subord(text))\n",
    "        \n",
    "    dataframe[\"Causal_Coherence\"] = causal_coherence_\n",
    "    dataframe[\"Longest_Causal_Sequence\"] = total_length_causal\n",
    "    dataframe[\"IntraSentence_Causality\"] = causal_intra_sent\n",
    "    \n",
    "    #dataframe.to_csv(f'data/{name_save}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ad1380-0204-48f7-9882-6d727b81d052",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Chronologie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da77bbc2-fa58-4df6-888a-5d3ec3568070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_chrono(text_list, dataframe, name_save = 'Test_Story_withVariable'):\n",
    "\n",
    "    chrono_func = Chronology()\n",
    "    date_presence, porp_time_change, logic_temp_order, logic_tense_order = [], [], [], []\n",
    "    for text in text_list:\n",
    "        date_presence.append(chrono_func.bin_date(text))\n",
    "        prop_time, logic = chrono_func.special_chrono(text)\n",
    "        porp_time_change.append(prop_time)\n",
    "        logic_temp_order.append(logic)\n",
    "        logic_tense_order.append(chrono_func.tense(text))\n",
    "        \n",
    "    dataframe[\"Presence_Dates\"] = date_presence\n",
    "    dataframe[\"Logic_order_temporality\"] = logic_temp_order\n",
    "    dataframe[\"Prop_temp_use\"] = porp_time_change\n",
    "    dataframe[\"Logic_order_conjuguation\"] = logic_tense_order\n",
    "    \n",
    "    #dataframe.to_csv(f'data/{name_save}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596a8b0b-cb82-4bcd-b5c5-5446bc4c0628",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18828174-2122-44f9-8a3a-00d2c91c2ec1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Start by computing and saving Characters Variables\n",
    "compute_characters(valid_list, df_posts_valid, name_save = 'Valid_Story_withVariable')\n",
    "compute_characters(test_list, df_posts_test, name_save = 'Test_Story_withVariable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45b258cf-54ff-42b8-81a3-076403c674b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\homer\\AppData\\Local\\Temp\\ipykernel_2008\\3901473308.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"Intrigue_Diversity\"] = diversity_\n",
      "C:\\Users\\homer\\AppData\\Local\\Temp\\ipykernel_2008\\3901473308.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"Intrigue_Sentence_Homogeneity\"] = homogeneity_\n",
      "C:\\Users\\homer\\AppData\\Local\\Temp\\ipykernel_2008\\3901473308.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"Intrigue_Consistence\"] = consistence_\n"
     ]
    }
   ],
   "source": [
    "#Compute theme and Intrigue in Story\n",
    "#new_valid = pd.read_csv(\"data/Valid_Story_withVariable.csv\")\n",
    "#new_test = pd.read_csv(\"data/Test_Story_withVariable.csv\")\n",
    "#compute_themes(train_list, valid_list, new_valid, name_save = 'Valid_Story_withVariable')\n",
    "#compute_themes(train_list, test_list, new_test, name_save = 'Test_Story_withVariable')\n",
    "compute_themes(train_list, valid_list, df_posts_valid, name_save = 'Valid_Story_withVariable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a123c28f-7ac4-4462-80ce-b0f70be97471",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Compute Presence of conflict\n",
    "#new_valid = pd.read_csv(\"data/Valid_Story_withVariable.csv\")\n",
    "#new_test = pd.read_csv(\"data/Test_Story_withVariable.csv\")\n",
    "#compute_conflict(valid_list, new_valid, name_save = 'Valid_Story_withVariable')\n",
    "#compute_conflict(test_list, new_test, name_save = 'Test_Story_withVariable')\n",
    "compute_conflict(valid_list, df_posts_valid, name_save = 'Valid_Story_withVariable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36f64d34-7391-44d8-92c2-7e7e71d28014",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ceaf7631e944c1b7265cda27a6545b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/688 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5e4de0b60749e49eb7f03b7925f61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53841754dd304c5e825b4ae27817a9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92de1fc6f3d5405da15879589f235717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004c68f2580b4b90b760940ba23d9817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#Compute causal relations of story\n",
    "new_valid = pd.read_csv(\"data/Valid_Story_withVariable.csv\")\n",
    "new_test = pd.read_csv(\"data/Test_Story_withVariable.csv\")\n",
    "compute_causality(valid_list, new_valid, name_save = 'Valid_Story_withVariable')\n",
    "compute_causality(test_list, new_test, name_save = 'Test_Story_withVariable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b696318c-1642-4c80-83e7-024ff806b16b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\homer\\AppData\\Local\\Temp\\ipykernel_2008\\1794076012.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"Presence_Dates\"] = date_presence\n",
      "C:\\Users\\homer\\AppData\\Local\\Temp\\ipykernel_2008\\1794076012.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"Logic_order_temporality\"] = logic_temp_order\n",
      "C:\\Users\\homer\\AppData\\Local\\Temp\\ipykernel_2008\\1794076012.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"Prop_temp_use\"] = porp_time_change\n",
      "C:\\Users\\homer\\AppData\\Local\\Temp\\ipykernel_2008\\1794076012.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[\"Logic_order_conjuguation\"] = logic_tense_order\n"
     ]
    }
   ],
   "source": [
    "#Compute temporality and space\n",
    "#new_valid = pd.read_csv(\"data/Valid_Story_withVariable.csv\")\n",
    "#new_test = pd.read_csv(\"data/Test_Story_withVariable.csv\")\n",
    "#compute_chrono(valid_list, new_valid, name_save = 'Valid_Story_withVariable')\n",
    "#compute_chrono(test_list, new_test, name_save = 'Test_Story_withVariable')\n",
    "compute_chrono(valid_list, df_posts_valid, name_save = 'Valid_Story_withVariable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c301805-c9af-45e7-879e-7b3de2c3c150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
